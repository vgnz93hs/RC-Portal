/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at http://mozilla.org/MPL/2.0/. */

package org.mozilla.fenix.ui.efficiency.logging

import org.mozilla.fenix.ui.efficiency.factory.logging.StepDescriptor
import org.mozilla.fenix.ui.efficiency.factory.logging.StepLogger
import org.mozilla.fenix.ui.efficiency.factory.steps.StepResult

/**
 * TimedReporter
 *
 * What it does:
 * - Emits a structured narrative of test execution to stdout via ConsoleLogger.
 * - Measures timing for each scope and adds slow warnings (⚠️ SLOW) using configurable thresholds.
 * - Optionally forwards structured step events into the existing factory logging pipeline (StepLogger),
 *   so we can retain artifacts like summary.log / details.jsonl while iterating on console UX.
 *
 * Why it is built this way:
 * 1) Keep tests clean ("what"), keep mechanics in the harness ("how").
 *    - Tests should express intent. Logging and tracing should be automatic.
 *    - This is particularly important once tests are dynamically generated by factories,
 *      CI config, or reflection-based enumeration of pages/components.
 *
 * 2) Single place humans go to debug execution.
 *    - This logger provides a single cohesive stream: STEP -> CMD -> LOC.
 *    - It reduces reliance on searching logcat for scattered lines across tags/classes.
 *
 * 3) Accessibility + cognitive load.
 *    - Structured indentation and consistent tokens reduce scanning effort.
 *    - Distinct colors encode meaning, and mis-ordering is visually obvious.
 *
 * 4) Future-ready for dynamic generation + AI workflows.
 *    - Once we can generate test permutations (pages x states), we need a reliable way to
 *      *see* what actually ran. The log stream becomes a ground truth record.
 *    - Longer term, this same structure can serve as:
 *        - an execution trace for mapping to TestRail or reports,
 *        - a "test creation grammar" for AI agents to generate actions safely,
 *        - an input to self-healing (rewrite the call-stack / navigation path based on failures).
 *
 * Important design details:
 * - The start message is logged on startStep/startCmd/startLoc.
 * - The completion message is logged on end* and is intentionally concise (no duplication).
 * - We measure "wall time" as overall elapsed real-world time for the test run.
 */
class TimedReporter(private val forwarder: StepLogger? = null) {

    private data class Event(
        val id: String,
        val name: String, // start message ("Attempting ...")
        val type: Type,
        val level: Int, // indentation level
        val startNs: Long,
    )

    /**
     * STEP: highest-level intent (e.g., "Navigate to BookmarksPage").
     * CMD : custom command / helper (e.g., "click menu item", "verify page loads").
     * LOC : element lookup / verification.
     */
    enum class Type { STEP, CMD, LOC }

    /**
     * Slow thresholds are intentionally opinionated defaults. I fully expect these to change.
     *
     * Why defaults exist:
     * - They provide immediate value (highlighting unexpected waits) without requiring tuning.
     * - They encourage treating test speed as a first-class signal, not an afterthought.
     *
     * Future direction:
     * - Allow overrides by system properties so CI can tune thresholds per device tier.
     *   e.g. -DslowLocMs=400, -DslowCmdMs=1200
     */
    data class Thresholds(
        var stepMs: Long = 1500,
        var cmdMs: Long = 800,
        var locMs: Long = 250,
    )

    /**
     * Aggregated timing + counters for summaries.
     *
     * Notes:
     * - Totals for STEP/CMD/LOC reflect only instrumented scopes.
     * - "Wall time" is the overall elapsed real-world time (start -> end) and includes
     *   uninstrumented work (setup/teardown, system scheduling, sleeps, etc.).
     */
    data class Totals(
        var steps: Int = 0,
        var cmds: Int = 0,
        var locs: Int = 0,
        var oks: Int = 0,
        var fails: Int = 0,
        var stepMs: Double = 0.0,
        var cmdMs: Double = 0.0,
        var locMs: Double = 0.0,
        var startNs: Long = System.nanoTime(),
    )

    private val stack = ArrayDeque<Event>()
    private val thresholds = Thresholds()
    private val totals = Totals()

    /**
     * Reset per test. Called from BaseTest.setUp().
     *
     * Why reset here:
     * - Parameterized tests (and retries) reuse the same class instance patterns in some setups.
     * - Reset ensures summary only reflects the current test execution.
     */
    fun reset() {
        stack.clear()
        totals.steps = 0
        totals.cmds = 0
        totals.locs = 0
        totals.oks = 0
        totals.fails = 0
        totals.stepMs = 0.0
        totals.cmdMs = 0.0
        totals.locMs = 0.0
        totals.startNs = System.nanoTime()
    }

    fun startStep(id: String, name: String, level: Int = 0) {
        ConsoleLogger.step(level, name)
        forwarder?.stepStart(StepDescriptor(id, name, mapOf("type" to "STEP")))
        stack.addLast(Event(id, name, Type.STEP, level, System.nanoTime()))
        totals.steps += 1
    }

    fun startCmd(id: String, name: String, level: Int = 1) {
        ConsoleLogger.cmd(level, name)
        forwarder?.stepStart(StepDescriptor(id, name, mapOf("type" to "CMD")))
        stack.addLast(Event(id, name, Type.CMD, level, System.nanoTime()))
        totals.cmds += 1
    }

    fun startLoc(id: String, name: String, level: Int = 2) {
        ConsoleLogger.loc(level, name)

        // LOC forwarding is intentionally enabled during PoC:
        // - Helpful to debug flaky selectors and verify element visibility issues quickly.
        // - Later, once the signal is proven, we may choose to:
        //     * not forward LOC to file sinks (too chatty),
        //     * or sample them,
        //     * or aggregate them into a single "batch verification" record per command.
        forwarder?.stepStart(StepDescriptor(id, name, mapOf("type" to "LOC")))

        stack.addLast(Event(id, name, Type.LOC, level, System.nanoTime()))
        totals.locs += 1
    }

    private fun endEvent(success: Boolean, message: String) {
        val ev = stack.removeLastOrNull() ?: return

        val elapsedMs = (System.nanoTime() - ev.startNs) / 1_000_000.0
        val slow = when (ev.type) {
            Type.STEP -> elapsedMs >= thresholds.stepMs
            Type.CMD -> elapsedMs >= thresholds.cmdMs
            Type.LOC -> elapsedMs >= thresholds.locMs
        }

        val msText = "%.1f".format(elapsedMs)
        val warnText = if (slow) " ⚠️ SLOW ($msText ms)" else " ($msText ms)"

        // Policy: completion messages are concise (no duplication of the start message).
        // Also: avoid empty message output (helps when callers forget to pass a message).
        val completionText =
            (message.takeIf { it.isNotBlank() } ?: (if (success) "OK" else "FAILED")) + warnText

        if (success) {
            ConsoleLogger.ok(ev.type, ev.level, completionText)
            totals.oks += 1
        } else {
            ConsoleLogger.err(ev.type, ev.level, completionText)
            totals.fails += 1
        }

        when (ev.type) {
            Type.STEP -> totals.stepMs += elapsedMs
            Type.CMD -> totals.cmdMs += elapsedMs
            Type.LOC -> totals.locMs += elapsedMs
        }

        // Forward end result to existing sinks (optional).
        forwarder?.let {
            val descriptor = StepDescriptor(ev.id, ev.name, mapOf("type" to ev.type.name))
            val result: StepResult = if (success) StepResult.Ok else StepResult.Fail(message)
            it.stepEnd(descriptor, result)
        }
    }

    // Default messages are empty so callers intentionally decide what completion means.
    fun endStep(success: Boolean = true, message: String = "") = endEvent(success, message)
    fun endCmd(success: Boolean = true, message: String = "") = endEvent(success, message)
    fun endLoc(success: Boolean = true, message: String = "") = endEvent(success, message)

    /**
     * Human-readable summary.
     *
     * Metrics:
     * - Wall time: overall elapsed real-world time (start -> end).
     * - STEP/CMD/LOC totals: sum of measured scope durations.
     *
     * Interpretation:
     * - If STEP total ≈ wall time, your top-level step wrapped nearly all work (good).
     * - If wall time is much larger, uninstrumented work may be dominating (setup/teardown, sleeps).
     * - This can later be exported to JSON for dashboards / trend tracking.
     */
    fun printSummary() {
        val wallMs = (System.nanoTime() - totals.startNs) / 1_000_000.0

        val stepAvg = totals.stepMs / (if (totals.steps == 0) 1 else totals.steps)
        val cmdAvg = totals.cmdMs / (if (totals.cmds == 0) 1 else totals.cmds)
        val locAvg = totals.locMs / (if (totals.locs == 0) 1 else totals.locs)

        ConsoleLogger.info(0, "=== TEST SUMMARY ===")
        ConsoleLogger.info(1, "Steps: ${totals.steps} (total ${"%.1f".format(totals.stepMs)} ms, avg ${"%.1f".format(stepAvg)} ms)")
        ConsoleLogger.info(1, "Commands: ${totals.cmds} (total ${"%.1f".format(totals.cmdMs)} ms, avg ${"%.1f".format(cmdAvg)} ms)")
        ConsoleLogger.info(1, "Locators: ${totals.locs} (total ${"%.1f".format(totals.locMs)} ms, avg ${"%.1f".format(locAvg)} ms)")
        ConsoleLogger.info(1, "Successes: ${totals.oks}   Failures: ${totals.fails}")
        ConsoleLogger.info(1, "Wall time: ${"%.1f".format(wallMs)} ms")
    }
}
